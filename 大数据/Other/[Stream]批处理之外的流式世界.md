数据流处理在大数据当中是越来越重要，有很好的理由。 其中：

(1) 业务渴望更及时的数据，并且切换到流是实现更低延迟的好方法。

(2) 在现代业务中越来越普遍的庞大的无限数据集使用为这种无休止的数据量设计的系统更容易处理。

(3) 随着时间的推移，处理数据会更加均匀，从而产生更一致和可预测的资源消耗(Processing data as they arrive spreads workloads out more evenly over time, yielding more consistent and predictable consumption of resources.)。

尽管这种业务需求驱动在流式处理中浪潮逐渐兴起，但与批处理相比，现存的流式处理系统仍然相对来说不成熟，这使得最近在这个领域产生了许多令人兴奋的，积极的发展。讨论流式处理，有些问题必须要先搞清楚：

这一篇文章将涵盖一些基本的背景信息，并在深入了解时域(time domains)的细节之前澄清一些术语，以及对批处理和流式处理的数据处理常见方法的高级概述。

### 1. 背景

首先，我将介绍一些重要的背景信息，这将有助于我构建将要讨论的其它主题。我们将在三个具体部分中进行：

(1) 术语：谈论复杂的话题要精确定义术语。对于某些在当前使用中有无法解释清楚(有歧义)的术语，我会尝试确定我所说的意思。

(2) 能力：我将介绍流式处理系统的缺点。我还将提出我认为数据处理系统建设者需要采纳的思路，以满足现代数据消费者的需求。

(3) 时间概念：我将介绍与数据处理相关的两个主要时间概念，展示它们之间的关系，并指出这两个概念的一些困难。

#### 1.1 什么是流?

在进一步讨论之前，我们首先弄清楚一件事情：什么是流(streaming)？ `流`这个术语在今天有不同的含义(为了简单起见，直到现我一直这样松散简单的理解它)，这可能会导致对真正的流是什么以及流系统能用来干什么产生误解。因此，我在一定程度上更精确地定义这个术语。

问题的关键在于许多东西应该用它们是什么来进行描述(例如，无限数据处理(unbounded data processing)，近似结果(approximate results)等)，但是它们却是通过是如何实现进行描述的(例如，通过流执行引擎)(have come to be described colloquially by how they historically have been accomplished (i.e., via streaming execution engines))。这种缺乏精确性的术语决定了流真正意味着什么，并且在某些情况下，带有这种负担的流系统，意味着它们的能力只被限制在`流`经常被描述的特性上，诸如近似或推测性结果(burdens streaming systems themselves with the implication that their capabilities are limited to characteristics frequently described as “streaming,” such as approximate or speculative results)。考虑到设计良好的流系统与现有任何的批处理引擎一样能够产生正确的，一致的，可重复的结果，所以我倾向于将流这个术语理解为更具体的含义：`一种为无限数据集设计的数据处理引擎`(a type of data processing engine that is designed with infinite data sets in mind)。(为了完整起见，可能值得一提的是，这个定义包括真正的流和微批量实现)。

至于`流`其他常见描述(As to other common uses of streaming)，这里我听到一些，每一个都用更精确的术语进行描述，建议我们整个社区都应该尝试采用：

(1) 无限数据(Unbounded Data)：一种不断增长的，实质上是无限的数据集。这些通常被称为`流数据`。然而，当使用`流`(streaming)和`批`(batch)来描述数据集时，这是有问题的，因为如上所述，`流`和`批`只是意味着使用哪种类型的执行引擎来处理数据集(译者注:`streaming`和`batch`可以理解为在处理数据的执行引擎上的表述)。所讨论的这两类数据集之间的关键区别实际上是它们的有限性，因此最好用能够描述它们之间区别的术语来表示它们。因此，我将无限的`streaming`数据集称为无限数据(unbounded data)，将有限的`batch`数据集称为有限数据(bounded data)。

(2) 无限数据处理(Unbounded data processing)：一种持续处理数据的模式，应用于上述类型的无限数据。尽管我个人喜欢使用术语`流`来描述这种类型数据的处理，但在这种上下文的情况下它使用又意味着使用流执行引擎，这很容易产生误导。批处理引擎的重复运行已经被用来处理无限数据，因为批处理系统是第一个被构想出来的(相反，设计良好的流处理系统同样能够处理有限数据上的`批处理`负载)。因此，为了清楚起见，我将简单地称之为无限的数据处理。(译者注:流处理引擎和批处理引擎都能够处理无限数据，因此无限数据不能使用流`streaming`来描述)

(3) 低延迟，近似或推测结果(Low-latency, approximate, and/or speculative results)：这些类型的结果通常与流处理引擎有关。批处理系统在设计之初就没有考虑到低延迟或推测性结果。当然，批量引擎完全可以产生近似的结果。因此，与上面的术语一样，将这些结果描述为它们是什么(低延迟，近似或推测)比通过它们是如何实现的(通过流式引擎)要好得多。

从这里开始，当我使用`流`(streaming)这个术语时，你都可以假设我的意思是一个为无限数据集而设计的处理引擎。当我指的是上述其他术语时，我会明确地说出无限数据，无限数据处理或低延迟/近似/推测的结果。

#### 1.2 streaming的局限性

接下来，让我们谈谈一下流处理系统可以做什么，不可以做什么，重点放在可以什么上; 我想在以前博客中遇到的最大的问题之一就是一个精心设计的流处理系统的性能如何。流处理系统长期以来一直被认为提供低延迟，不准确/推测结果，通常与功能更强大的批处理系统相结合，以提供最终的正确结果，即Lambda架构。

对于那些还不熟悉Lambda架构的人来说，Lambda的基本的思想就是，流处理系统与批处理系统一起运行，执行一样的计算。流处理系统为你提供低延迟，不准确的结果(或者是因为使用近似算法，或者是因为流处理系统本身不能提供正确性)，一段时间后，批处理系统会为你提供正确的输出。最初由Twitter的Nathan Marz(Storm的创始人)提出，最终也相当的成功，因为事实上，在当时这是一个非常好的主意。对流处理引擎的正确性有些失望，批处理引擎实际上也没有你想象的那样笨重(unwieldy)，所以Lambda给了你一个鱼与熊掌两者兼得的方法。不幸的是，维护Lambda系统非常麻烦：你需要构建，配置和维护两个独立版本的管道，然后以某种方式合并最后两个管道的结果。

作为一个花费了好几年时间研究一个强一致性流处理引擎的人，我也发现了Lambda架构的原理有点令人讨厌。毫不奇怪，我也非常赞同Jay Kreps[Lambda架构的质疑](https://www.oreilly.com/ideas/questioning-the-lambda-architecture) 博文的观点。这是第一个对双引擎执行必要性的远见陈述。Kreps在使用像Kafka这样的可重放系统作为流连接器的情况下解决了可重复性的问题，甚至提出了Kappa架构，这基本上意味着使用对手头作业设计良好的系统可以只运行一个管道。我虽然不相信这个概念需要一个新的名字，但我原则上完全支持这个概念。

说实话，我会更进一步认为，精心设计的流处理系统实际上可以提供比批量处理更多的功能。Modulo perhaps an efficiency delta，不会像现在这样存在批处理系统。对于Flink来说，这个想法是非常重要的，即使是在批处理模式下，也可以建立一个全时全流式系统(building a system that’s all-streaming-all-the-time under the covers, even in “batch” mode)。



#### 1.3 事件时间 与 处理时间


### 2. 数据处理模式






















原文:https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101

资料:http://blog.csdn.net/ccjhdopc/article/details/51121538

https://yq.aliyun.com/articles/73252?t=t1
