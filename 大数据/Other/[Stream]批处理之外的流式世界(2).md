---
layout: post
author: sjf0115
title: Stream 批处理之外的流式世界(2)
date: 2018-01-09 17:54:01
tags:
  - Stream

categories: Stream
---

### 1. 总结和路线图

在[Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101)中，我们首先澄清了一些术语。然后我开始区分有限数据和无限数据。有限数据源的大小是有限的，通常被称为`batch`数据。无限数据源可能具有无限大小，并且通常被称为`streaming`数据。我尽量避免使用`batch`和`streaming`术语来指代数据源，因为这些名称带有一些误导并经常受到限制。

然后，我继续定义了批处理引擎和流引擎之间的区别：批处理引擎是那些仅为有限数据而设计的引擎，而流引擎是设计时考虑到了无限数据。我的目标是在引用执行引擎时只使用`batch`和`streaming`术语。

在术语之后，我介绍了与处理无限数据有关的两个重要概念。我首先确定了`事件时间`(事件发生的时间)和`处理时间`(处理期间观察到时间)之间的关键区别。这为[Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101)提出的主要论点之一提供了基础：如果你关心事件实际发生的正确性和上下文，则必须分析与固有事件时间相关的数据，而不是分析它们的在处理过程中遇到处理时间。

然后，我介绍了窗口的概念(即，将数据集按时间界线划分)，这是一种常见的方法，用于处理无限数据源在技术上永远不会结束的事实。窗口化策略中比较简单的是固定窗口的和滑动窗口，也还有更复杂的窗口类型，例如会话窗口(其中窗口由数据本身的特征定义，例如捕获每个用户的活动会话，紧跟不活跃的间隙)应用也比较广泛。

除了这两个概念之外，我们现在要仔细研究一下三个概念：
- `Watermarks`是关于事件时间输入完整性的概念。具有时间X值的`watermark`表示：`已经观察到所有输入数据并且事件时间小于X`。因此，当不知道无限数据源什么时候结束时，`watermark`就用作进度的度量。
- `Triggers`是一种机制，用于声明窗口输出何时应相对于某个外部信号实现。触发器在选择何时发送输出方面提供了灵活性。它们还可以随着时间的变化多次观察窗口的输出(observe the output for a window multiple times as it evolves)。这为随着时间的推移而修改结果提供了可能，这又开启了随时间改进结果的大门，这允许在数据到达时提供推测结果，并且随时间处理上游数据的变化或相对于`watermark`迟到的数据(例如，移动场景 ，其中某个人的电话在该人离线时记录各种动作和他们的事件时间，然后在重新获得连接时继续上传这些事件进行处理。)
- `Accumulation`

最后，因为我认为理解这些概念之间的关系比较容易，我们将重新回顾以前的问题，并在回答下面四个问题中探索新的问题，所有这些问题对于每一个无限数据处理问题都是至关重要的：

(1) `What`计算出什么样的结果？这个问题由流水线内的`转换类型`来回答。这包括诸如计算总和，构造直方图，训练机器学习模型等。这也是经典批处理回答的问题。

(2) `Where`事件发生的时间是在哪里计算的？ 这个问题将由管道内的`基于事件时间的窗口`来回答。这包括[Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101)介绍的窗口常见示例(固定，滑动和会话窗口)，不使用窗口概念的用例(例如，[Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101)中描述的与时间无关的处理；经典的批处理也通常属于这种类别)以及其他更复杂的窗口类型，例如有时间限制的拍卖。还要注意，也可以包含处理时间窗口，如果当记录到达系统时将摄入时间作为事件时间时。

(3) `When`处理时间什么时候被物化的？这个问题通过使用`watermark`和`触发器`来回答。在这个主题上有无限的变化，但是最常见的模式是使用`watermark`来描述给定窗口的输入是否完成，使用触发器允许指定早期结果(在窗口完成之前发送推测的部分结果)和后期结果(`watermark`仅仅是对完整性的估计，在`watermark`声明给定窗口的输入完成之后可能到达更多的输入数据的情况)。

(4) `How`如何使结果更加精致？这个问题由所使用的累积(`accumulation`)类型来回答：丢弃(结果都是独立的和不同的)，累积(后来的结果建立在先前的结果之上)，或者累积和撤回(累积值加上撤回先前发送的已被触发值)(the accumulating value plus a retraction for the previously triggered value(s) are emitted)。

在这篇文章的其余内容，我们将更详细地讨论这些问题。

### 2. Streaming 101 总结

首先，让我们回顾一下在[Streaming 101](https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-101)中提出的一些概念，但是这次还有一些详细的例子，这些例子将有助于我们更好的理解这些概念。

#### 2.1 What: transformations

在经典的批处理应用中的转换操作回答了这个问题：`计算出什么样的结果？`，即使你们中的很多人可能对经典的批处理已经很熟悉了，我们还是从那里开始，因为它是我们添加所有其他的概念的基础。

在本节中，我们将看到一个简单的例子：在由10个值组成的简单数据集上计算键控整数和。如果你想要一个更实际一点的话，你可以把它想象成一个个人团队通过把自己的独立分数结合在一起来玩某种手机游戏的整体得分。 您可以想象它对于计费和使用情况监控用例同样适用。

对于每个示例，我将包含一个`Dataflow Java SDK`伪代码的简短片段，以更好的了解管道的定义。从某种意义上说，这是伪代码，有时我会略作修改以使示例更清晰，更详细(比如使用具体的I/O源)，或者简化名称(`Java`中当前的触发器名称非常冗长；为了清晰，我将使用更简单的名称)。除了那些小的东西(其中大部分我在`Postscript`中明确列举)之外，基本上都是真实的`Dataflow SDK`代码。我还会在后面为那些对类似例子(可以编译和运行)感兴趣的人提供一个实际代码演练的链接。

如果你熟悉`Spark Streaming`或`Flink`等类似的工具，那么对于理解`Dataflow`代码是比较容易的。为了给你一个崩溃的过程，在数据流中有两个基本的术语：
- `PCollections`表示执行并行转换操作的数据集(可能是大数据集)(因此名称以`p`开头)。
- `PTransforms`，将其应用于`PCollections`来创建新的`PCollections`。`PTransforms`可以执行元素转换，可以将多个元素聚合在一起，也可以是其他`PTransforms`的复合组合。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Other/%E6%89%B9%E5%A4%84%E7%90%86%E4%B9%8B%E5%A4%96%E7%9A%84%E6%B5%81%E5%BC%8F%E4%B8%96%E7%95%8C-12.jpg?raw=true)

就我们的例子而言，我们首先假定认为`PCollection< KV<String，Integer> >`为`输入`(即由`Strings`和`Integer`的键/值对组成的`PCollection`，其中的`Strings`像是团队名称，`Integer`是对应团队的任意人的分数)。在现实世界的流水线中，我们将通过从`I/O`数据源读取原始数据(例如，日志记录)的`PCollection`来获取输入，然后通过将日志记录解析为适当的键/值对将其转换为`PCollection< KV<String，Integer> >`。 为了清楚起见，在第一个例子中，我将包含这些所有步骤的伪代码，但在随后的例子中，我忽略了`I/O`和解析部分。

因此，管道会简单地从`I/O`源读取数据，解析出团队/分数键值对，并计算每个团队的分数总和:
```
PCollection<String> raw = IO.read(...);
PCollection<KV<String, Integer>> input = raw.apply(ParDo.of(new ParseFn());
PCollection<KV<String, Integer>> scores = input.apply(Sum.integersPerKey());
```
上述代码从`I/O`源读取键/值对数据，其中以`String`(例如，团队名称)作为键和`Integer`(例如，团队每个成员分数)作为值。然后将每个键对应的值相加在一起以在输出集合中产生键对应数据的总和(例如一个团队的总得分)。

对于所有的例子来说，在看到描述管道的代码片段之后，我们将看看在具体数据集上执行该管道的动画渲染。更具体地说，我们将看到在的单个key的10个输入数据(唯一的一个key对应10个值)上执行管道的过程。在一个真正的管道中，你可以想象类似的操作将会在多台机器上并行执行，但是在我们的例子中尽量简单化。

每个动画在两个维度上绘制输入和输出：`事件时间`(在X轴上)和`处理时间`(在Y轴上)。因此，如粗的上升白线所示，管道从下到上的进度可实时观察。输入是圆圈，圆圈内的数字代表特定记录的值。当管道观察到它们时，它们开始改变之前灰色而变成白色。

当管道观察到值时，将它们进行累加，并最终将聚合结果输出。状态和输出由矩形表示，聚合值靠近顶部，矩形覆盖的区域表示部分事件时间和处理时间累加到结果中。对于下图中的管道，在经典的批处理引擎上执行时看起来就像这样：

































































































原文:https://www.oreilly.com/ideas/the-world-beyond-batch-streaming-102
