---
layout: post
author: sjf0115
title: Spark 性能调优之内存调优
date: 2018-04-06 11:28:01
tags:
  - Spark
  - Spark 优化

categories: Spark
permalink: spark-performance-memory-tuning
---

在调整内存使用情况时有三个注意事项：
- 对象使用的内存量（你可能希望你的整个数据集加载到内存中）
- 访问这些对象的成本
- 垃圾收集的开销

默认情况下，Java 对象的访问速度很快，但可以轻松消耗比其字段中的'原始'数据多2-5倍的空间。这是由于几个原因：
- 每个不同的 Java 对象都有一个 `object header`，大约有16个字节，包含诸如指向其类的指针等信息。对于数据非常少的对象（比如一个Int字段），这可能比数据更大。
- Java 字符串在原始字符串数据上具有大约40字节的开销（因为它们存储在一个 Char 数组中并保留额外的数据，例如长度），并且由于字符串内部使用 UTF-16 ，将每个字符存储为两个字节。因此，一个10个字符的字符串可以容易地消耗60个字节。
- 常见集合类（如HashMap和LinkedList）使用链接的数据结构，其中每个条目（例如： Map.Entry）都存在一个'包装器'对象。该对象不仅具有 `header`，而且还有一个指向列表中下一个对象的指针（每个通常8个字节）。
- 基本类型的集合通常将它们存储为 `boxed` 对象，如java.lang.Integer。

本文中将首先概述 Spark 的内存管理，然后讨论用户在应用程序中更有效使用内存的具体策略。具体来说，我们将介绍如何确定对象的内存使用情况，以及如何改进，既可以通过更改数据结构，也可以通过以序列化格式存储数据实现。接下来我们将介绍调整 Spark 的缓存大小和 Java 垃圾回收器。

### 1. 内存管理概述

Spark中的可使用内存大部分属于两类：执行内存和存储内存。执行内存是指用于在 shuffle，join，排序和聚合中进行计算的内存，而存储内存指的是用于集群之间缓存和传播内部数据的内存。在Spark中，执行和存储共享统一区域（M）。 当不使用执行内存时，存储可以获取所有可用内存，反之亦然。 如有必要，执行可能会驱逐存储空间，但只能在总存储内存使用量低于特定阈值（R）时才执行。 换句话说，R描述了M中的一个子区域，其中缓存的块不会被驱逐。 由于执行的复杂性，存储可能不会执行。

























> Spark 版本:2.2.0

原文：http://spark.apache.org/docs/2.2.0/tuning.html#memory-tuning
