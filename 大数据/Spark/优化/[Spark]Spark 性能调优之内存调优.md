---
layout: post
author: sjf0115
title: Spark 性能调优之内存调优
date: 2018-04-06 11:28:01
tags:
  - Spark
  - Spark 优化

categories: Spark
permalink: spark-performance-memory-tuning
---

在调整内存使用情况时有三个注意事项：
- 对象使用的内存量（你可能希望你的整个数据集加载到内存中）
- 访问这些对象的成本
- 垃圾收集的开销

默认情况下，Java 对象的访问速度很快，但可以轻松消耗比其字段中的'原始'数据多2-5倍的空间。这是由于几个原因：
- 每个不同的 Java 对象都有一个 `object header`，大约有16个字节，包含诸如指向其类的指针等信息。对于数据非常少的对象（比如一个Int字段），这可能比数据更大。
- Java 字符串在原始字符串数据上具有大约40字节的开销（因为它们存储在一个 Char 数组中并保留额外的数据，例如长度），并且由于字符串内部使用 UTF-16 ，将每个字符存储为两个字节。因此，一个10个字符的字符串可以容易地消耗60个字节。
- 常见集合类（如HashMap和LinkedList）使用链接的数据结构，其中每个条目（例如： Map.Entry）都存在一个'包装器'对象。该对象不仅具有 `header`，而且还有一个指向列表中下一个对象的指针（每个通常8个字节）。
- 基本类型的集合通常将它们存储为 `boxed` 对象，如java.lang.Integer。

本文中将首先概述 Spark 的内存管理，然后讨论用户在应用程序中更有效使用内存的具体策略。具体来说，我们将介绍如何确定对象的内存使用情况，以及如何改进，既可以通过更改数据结构，也可以通过以序列化格式存储数据实现。接下来我们将介绍调整 Spark 的缓存大小和 Java 垃圾回收器。

### 1. 内存管理概述

Spark中的可使用内存大部分属于两类：执行内存和存储内存。执行内存是指用于在 shuffle，join，排序和聚合中进行计算的内存，而存储内存指的是用于集群之间缓存RDD和广播部数据的内存。存储内存和执行内存共享同一块空间(Unified Memory)，可以动态占用对方的空闲区域。`spark.storage.storageFraction` 参数，设定了双方各自拥有的空间的范围。双方的空间都不足时，则存储到硬盘，若己方空间不足而对方空余时，可借用对方的空间（存储空间不足是指不足以放下一个完整的 Block）。执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 '归还' 借用的空间。由于执行的复杂性，存储内存的空间被对方占用后，无法让对方 '归还'。

这种设计确保了几种理想的性能。首先，不使用缓存的应用程序可以将整个空间用作执行内存，避免不必要的磁盘溢出。其次，使用高速缓存的应用程序可以保留最小的存储空间，使其数据块不会被驱逐。最后，这种方法为各种工作负载提供了合理的开箱即用性能，而不需要要求用户知道内存如何分配内存。

尽管有两种相关配置，但一般用户不需要调整它们，因为默认值适用于大多数工作负载：
- `spark.memory.fraction` : 控制执行内存和存储内存共享的统一内存大小（Spark2.+ 默认值为0.6，表示占用可用内存的60%，Spark1.6默认为0.75）。其余空间（40％）用于用户定义的数据结构，Spark中的内部元数据，以及在稀疏和异常大的记录情况下防止OOM错误。
- `spark.memory.storageFraction` 控制存储内存大小（默认为0.5，表示占用统一内存的50%）。

应该设置 `spark.memory.fraction` 的值，以便满足 JVM 老年代或'终生代'的堆空间。有关详细信息，请参阅下面的高级GC调整讨论。

### 2. 确定内存消耗

计算数据集所需的内存消耗量的最佳方式是创建 RDD，将其放入缓存，然后查看Web UI中的'存储'页面。该页面会告诉你RDD占用了多少内存。

要估计特定对象的内存消耗，请使用 SizeEstimator 的 estimate 方法。这对于尝试使用不同的数据布局来调整内存使用量以及确定广播变量在每个执行程序堆上占用的空间量很有用。

### 3. 数据结构优化

减少内存消耗的第一种方法是避免增加开销的Java功能，例如基于指针的数据结构和包装对象。有几种方法可以做到这一点：
- 设计数据结构以优先选择对象数组和原始类型，不要使用 Java 或 Scala 集合类（例如HashMap）。fastutil　库为提供了一些方便的原始类型的集合类，与Java标准库兼容的。
- 尽可能避免使用许多小对象和指针的嵌套结构。
- 考虑使用数字ID或枚举对象来代替字符串键。
- 如果RAM少于32 GB，请设置JVM标志 `-XX：+ UseCompressedOops` 使指针为4个字节而不是8个。可以在 `spark-env.sh` 中添加这些选项。

### 4. 序列化RDD存储

尽管优化之后，如果的对象仍然比较大，无法进行高效存储，一种简单的降低内存使用量的方法是以序列化的形式存储对象，使用[RDD persistence API](http://smartsi.club/2018/03/16/spark-base-rdd-persistence/)中的序列化存储级别（例如 `MEMORY_ONLY_SER`）。Spark 然后将每个 RDD 分区存储为一个大字节数组。以序列化格式存储数据的唯一缺点是访问速度较慢，这是由于必须对每个对象进行反序列化导致的。如果你想以序列化的形式缓存数据，我们强烈推荐使用 Kryo，因为它比 Java 序列化（当然也比原始的Java对象）要小得多。

### 5. 垃圾回收调优

当在你程序存储的 RDD 层面上有很大的 `churn` 时，JVM 垃圾回收可能会有问题。只读取一次 RDD 然后在上面执行多次操作，应用程序通常不会有问题。当 Java 需要驱逐旧对象以腾出空间给新的对象时，它需要跟踪所有的 Java 对象并查找不使用的对象。这里需要记住的是垃圾回收的成本与 Java 对象的数量成正比，因此使用较少对象的数据结构（例如，使用 Ints 数组而不使用 LinkedList）大大降低成本。一种更好的方法是如上所属以序列化的形式保存对象：现在每个 RDD 分区只有一个对象（一个字节数组）。在尝试其他技术之前，如果GC有问题，可以尝试使用上面方法序列化缓存。

由于任务的工作内存（运行任务所需的空间）与缓存在节点上的 RDD 之间的干扰，GC也可能成为问题。我们下面讨论如何控制分配给 RDD 缓存的空间来缓解这一问题。

#### 5.1 测量GC的影响

GC调优的第一步是收集有关垃圾回收的发生频率以及GC花费时间的统计数据。这可以通过添加 `-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps` 到 Java 选项来完成。有关将 Java 选项传递给Spark作业的信息，请参阅[配置指南](http://spark.apache.org/docs/2.2.0/configuration.html#Dynamically-Loading-Spark-Properties)。下次运行 Spark 作业时，每次发生垃圾回收时都会在工作节点上的日志中看到消息。请注意，这些日志位于集群的工作节点上（在其工作目录中的 stdout 文件中），而不是在你的驱动程序上。

#### 5.2 高级GC优化








> Spark 版本:2.2.0

原文：http://spark.apache.org/docs/2.2.0/tuning.html#memory-tuning
