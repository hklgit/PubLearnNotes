### 1. 概述

Hadoop分布式文件系统(`HDFS`)是一个分布式文件系统，设计初衷是可以在商用硬件上运行。它与现有的分布式文件系统有许多相似之处。但是，与其他分布式文件系统的也有显著的差异。`HDFS`具有高容错能力，可以部署在低成本的硬件上。`HDFS`提供对应用程序数据的高吞吐量访问，适用于具有大数据集的应用程序。`HDFS`放宽了一些POSIX要求，以便对文件系统数据进行流式访问。`HDFS`最初是作为`Apache Nutch`网络搜索引擎项目的基础架构构建的。`HDFS`是`Apache Hadoop Core`项目的一部分。项目URL为: http://hadoop.apache.org/

### 2. 设想与目标

#### 2.1 硬件故障

 硬件故障很常见并不感到意外。`HDFS`实例可能由上百或上千台服务器机器组成，每台机器存储部分文件系统的数据。事实上，有大量的组件，并且每个组件具有不一定的故障概率，这意味着`HDFS`的某些组件总是不起作用的。因此，故障检测和快速自动恢复是`HDFS`的核心架构。

#### 2.2 流式数据访问

在`HDFS`上运行的应用程序需要流式访问其数据集。`HDFS`不是用于提供普通应用访问的文件系统。`HDFS`的设计更多为了批量处理，而不是与用户进行交互。重点是数据访问的高吞吐量，而不是数据访问的低延迟。POSIX施加了许多没有必要为HDFS应用程序所需的硬要求。POSIX语义在几个关键领域已被交易，以提高数据吞吐率。

#### 2.3 大数据集

在`HDFS`上运行的应用程序具有较大的数据集。`HDFS`中的文件大小一般为几GB或几TB。因此，`HDFS`被调整为支持大文件。它应该提供高聚合数据带宽并扩展到单集群中的数百个节点。它应该在一个实例中支持数千万个文件。

#### 2.4 简单一致性模型

HDFS数据访问模式为一次写入多次读取。文件一旦创建、写入和关闭后，除了追加和截断外，文件不再变化。将内容追加到文件末尾是支持的，但不能在任意位置更新文件。该假设简化了数据一致性问题，并实现了高吞吐量数据访问。`MapReduce`应用程序或Web爬虫程序应用程序与此模型完美匹配。

#### 2.5 '移动计算比移动数据便宜'

如果应用程序能够在其操作的数据附近执行，那么应用程序所请求的计算效率会更高。当数据集很大时，这一点更能体现。这样可以最大限度地减少网络拥塞并提高系统的整体吞吐量。我们假设将计算迁移到更靠近数据的位置比将数据移动到应用程序运行的位置更好。`HDFS`为应用程序提供接口，使其更靠近数据所在的位置。

#### 2.6 跨越异构硬件和软件平台的可移植性

`HDFS`被设计为可以从一个平台轻松地移植到另一个平台。这有助于`HDFS`作为大型应用程序的首选平台。

### 3. NameNode and DataNodes

`HDFS`是一个主/从结构。一个`HDFS`集群包含一个单独的`NameNode`，管理文件系统命名空间以及管理客户端对文件访问的主服务。除此之外，还有一些`DataNode`，通常集群中的每个节点都有一个`DataNode`，用于管理它们所运行节点相关的存储。`HDFS`公开文件系统命名空间，并允许用户数据存储在文件中。在内部，一个文件被分成一个或多个数据块，这些数据块被存储在一组`DataNode`中。`NameNode`执行文件系统命名空间操作，例如打开，关闭和重命名文件和目录等。它也决定数据块到`DataNode`的映射。`DataNode`负责为文件系统客户端的读写请求提供服务。`DataNode`还根据来自`NameNode`的指令执行数据块的创建，删除和复制。































备注:
```
Hadoop版本: 2.7.3
```

原文:http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html
