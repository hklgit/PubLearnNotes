---
layout: post
author: sjf0115
title: Hadoop 分布式缓存
date: 2018-08-04 14:32:17
tags:
  - Hadoop
  - Hadoop 优化

categories: Hadoop
permalink: hadoop-how-to-use-distributed-cache
---

Hadoop 分布式缓存能够在任务运行过程中即使将温江和存档复制到任务节点以供使用。为了节约网络带宽，在每一个作业中，各个文件通常只需要复制到一个节点一次。

### 1. 用法

对于使用 GenericOptionsParser 的工具来说，用户可以使用 `-files` 选项指定待分发的文件，文件内包含以逗号隔开的 URI 列表。文件可以存放在本地文件系统，HDFS 或其他 Hadoop 可读文件系统之中。如果尚未指定文件系统，则这些文件被默认为本地的。即使默认文件系统并非本地文件系统，这也成立。

用户可以使用 `-archives` 选项向自己的任务中复制存档文件（JAR文件，ZIP文件，tar文件等），这些文件会被解档到任务节点。

用户可以使用 `-libjars` 选项会把 JAR 文件添加到 Mapper 和 Reducer 任务的类路径中。如果作业 JAR 文件并没有包含库 JAR 文件，这点会很有用。

### 2. 工作机制

当用户启用一个作业时，Hadoop 会把 `-files`，`-archives` 和 `-libjars` 等选项所指定的文件复制到分布式文件系统（HDFS）上。在任务运行之前，节点管理器将文件从分布式文件系统复制到本地磁盘（缓存）使任务能够访问文件。此时，这些文件就被视为本地化了。从任务的角度来看，这些文件就已经在那了，以符号链接的方式指向任务的工作目录。此外，`-libjars` 指定的文件会在任务启动之前添加到任务的类路径中。

节点管理器为缓存中的文件各维护一个计数器来统计这些文件的使用情况。当任务即将运行时，该任务所使用的所有文件的对应计数器值增加1，当任务执行完毕之后，这些计数器的值减1。仅当文件不在使用中（计数器值为0），才有资格删除。当节点缓存的容量超过一定范围（默认为10GB）时，需要根据最近最少使用原则删除文件以腾出空间装载新文件。缓存的大小可以通过属性 `yarn.nodemanager.localizer.cache.target-size-mb` 来配置。

### 3. 分布式缓存API

由于可以通过 GenericOptionsParser 间接使用分布式缓存，大多数应用不需要使用分布式缓存API。然而，如果没有使用 GenericOptionsParser，那么可以使用 Job 中的API将对象放进分布式缓存中。以下是 Job 中相关的方法：
```java
public static void setCacheArchives
public static void addCacheArchive
public static void addArchiveToClassPath

public static void setCacheFiles
public static void addCacheFile
public static void addFileToClassPath

public static void createSymlink
```

在缓存中可以存放两类对象：文件（File）和存档（Archives）。文件被直接放置在任务节点上，而存档会被解档之后再将具体文件放置在任务节点上。每种对象类型都包含三种方法：addCacheXXX，setCacheXXX 和 addXXXToClassPath。其中，addCacheXXX 方法将文件或者存档添加到分布式缓存，setCacheXXX 方法将一次性向分布式缓存添加一组文件或者存档，addXXXToClassPath 方法将文件或者存档添加到 MapReduce 任务的类路径上。下面将API与 GenericOptionsParser 选项做一个比较：

API|选项|描述
---|---|---
addCacheFile,setCacheFiles|-files file1,file2,...|将文件添加分布式缓存，以备将来被复制到任务节点
addCacheArchive,setCacheArchives|-archives archive1,archive2,...|将存档添加到分布式缓存，以备将来复制到任务节点，并在任务节点解档
addFileToClassPath|-libjars jar1,jar2,...|将文件添加分布式缓存，以备将来被复制到 MapReduce 类路径中。文件并不会解档，因此适合向类路径添加JAR文件
addArchiveToClassPath|无|将文件添加分布式缓存，以备将来被复制到 MapReduce 类路径中。当想向类路径添加目录和文件时，这种方式比较有用，因为用户可以创建一个包含指定文件的存档。

> add 和 set 方法中的输入参数URI是指在作业运行时位于共享文件系统（例如，HDFS）中的（一组）文件。而 GenericOptionsParser 选项（例如，-files）所指定的文件可以是本地文件，如果是本地文件的话，则会被复制到默认的共享文件系统中。

> 这也是使用Java API 和使用 GenericOptionsParser 的关键区别：Java API 中的 add 和 set 方法不会将指定文件复制到默认的共享文件系统中，但是 GenericOptionsParser 会这样做。

如果用的是老版本的 MapReduce API，可以在 `org.apache.hadoop.filecache.DistributedCache` 中找到同样的方法。通过如下方式添加文件到分布式缓存中：
```java
Configuration conf = new Configuration();  
Job job = new Job(conf, "wordcount");
DistributedCache.addCacheFile(new URI("/cachefile1"),job.getConfiguration());
```
再通过如下方式从分布式缓存中读取数据：
```java
Path[] cacheFiles = context.getLocalCacheFiles();
FileInputStream fileStream = new FileInputStream(cacheFiles[0].toString());
```

从任务中获取分布式缓存文件在工作机理上和以前是一样的：通过名称访问本地化的文件。之所以起作用，是因为 MapReduce 总会在任务的工作目录和添加到分布式缓存中的每个文件或存档之间建立符号化链接。存档被接档后就能使用嵌套的路径访问其中的文件。

来源于：Hadoop权威指南
