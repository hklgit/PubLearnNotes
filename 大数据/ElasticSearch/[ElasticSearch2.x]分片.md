
### 1. 分片预分配

一个分片存在于单个节点，但一个节点可以拥有多个分片。想象一下我们创建拥有两个主分片的索引而不是一个，下面创建拥有两个主分片没有副本分片的索引：
```json
PUT /my_index
{
  "settings": {
    "number_of_shards":   2,
    "number_of_replicas": 0
  }
}
```
当只有一个节点时，两个分片被分配到相同的节点。从应用程序的角度来看，一切都和之前一样运行。应用程序和索引进行通讯，而不是分片，现在还是只有一个索引。

这时，我们加入第二个节点，Elasticsearch 会自动将其中一个分片移动至第二个节点，如下图所示，当重新分配完成后，每个分片都将接近至两倍于之前的计算能力。

![image](https://www.elastic.co/guide/cn/elasticsearch/guide/2.x/images/elas_4402.png)

我们已经可以通过简单地将一个分片通过网络复制到一个新的节点来加倍我们的处理能力。 最棒的是，我们零停机地做到了这一点。在分片移动过程中，所有的索引搜索请求均在正常运行。

在 Elasticsearch 中新添加的索引默认被指定了五个主分片。 这意味着我们最多可以将那个索引分散到五个节点上，每个节点一个分片。 它具有很高的处理能力，还未等你去思考这一切就已经做到了！

#### 分片分裂

用户经常在问，为什么 Elasticsearch 不支持 分片分裂（shard-splitting）— 将每个分片分裂为两个或更多部分的能力。 原因就是分片分裂是一个糟糕的想法：

- 分裂一个分片几乎等于重新索引你的数据。它是一个比仅仅将分片从一个节点复制到另一个节点更重量级的操作。
- 分裂是指数的。起初你你有一个分片，然后分裂为两个，然后四个，八个，十六个，等等。分裂并不会刚好地把你的处理能力提升 50%。
- 分片分裂需要你拥有足够的能力支撑另一份索引的拷贝。通常来说，当你意识到你需要横向扩展时，你已经没有足够的剩余空间来做分裂了。

Elasticsearch 通过另一种方式来支持分片分裂。你总是可以把你的数据重新索引至一个拥有适当分片个数的新索引（参阅 重新索引你的数据）。 和移动分片比起来这依然是一个更加密集的操作，依然需要足够的剩余空间来完成，但至少你可以控制新索引的分片个数了。


### 2. 海量分片

#### 2.1 背景

一个新手可能会这么想：
```
我不知道这个索引将来会变得多大，并且过后我也不能更改索引的大小，
所以为了保险起见，还是给它设为 1000 个分片吧…
```

#### 2.2 代价
一千个分片——当真？在你买来 一千个节点 之前，你不觉得你可能需要再三思考你的数据模型然后将它们重新索引吗？

一个分片并不是没有代价的。记住：
- 一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU 运转。
- 每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好， 但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了。
- 用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度。

备注

适当的预分配是好的。但上千个分片就有些糟糕。我们很难去定义分片是否过多了，这取决于它们的大小以及如何去使用它们。 一百个分片但很少使用还好，两个分片但非常频繁地使用有可能就有点多了。 监控你的节点保证它们留有足够的空闲资源来处理一些特殊情况．

横向扩展应当分阶段进行。为下一阶段准备好足够的资源。 只有当你进入到下一个阶段，你才有时间思考需要作出哪些改变来达到这个阶段。
