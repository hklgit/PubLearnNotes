---
layout: post
author: sjf0115
title: Flink1.4 事件时间与无序处理
date: 2018-01-15 15:35:17
tags:
  - Flink

categories: Flink
---

流数据处理正在蓬勃发展，因为它可以提供最新新数据的更好洞察，以及从数据提取到分析的简化流程。现实世界中的数据生成一直是一个持续的过程(例如，Web服务器日志，移动应用程序中的用户活动，数据库事务或传感器读取数据)。正如其他人所指出的，到目前为止，大部分数据基础架构都是建立在这样的基本假设之上:`数据是有限和静态的`。

为了弥补连续数据生产和旧"批处理"系统局限性之间的这一根本差距，公司已经引入了复杂而脆弱(fragile)的端到端管道。现在流处理技术通过对数据进行建模和处理，从而减少了对复杂解决方案的需求，这些数据是以真实世界的事件形式出现的。

将数据建模以及将数据以流方式处理的想法当然不是最新的，市场上可用的数据流处理器也不是最新的。但是，一个新的流处理系统(包括Apache Flink)与旧的流处理系统(包括开源和专有的)提供了本质的区别。使用Flink进行数据流处理比传统概念上快速(实时)分析要应用广泛得多，包括对历史数据的分析，以及启用新一类的应用程序，这些应用程序很少或根本不使用以前旧技术。我们将详细研究一些应用程序，并展示Flink如何以及为何能够有效地支持这些应用程序：

(1) 无序数据的精准结果。在大多数流处理场景中，事件的顺序非常重要，通常事件到达数据处理集群的顺序与这些事件在现实世界中实际发生的时间不同。Flink是第一个开源系统，可以让开发人员控制事件时间，事件发生的时间，在乱序流处理中实现精确的结果。

(2) 会话和未对齐的窗口：对Web日志，机器日志和其他数据进行分析需要能够在会话中将事件进行分组。会话是未对齐窗口(unaligned windows)的一个典型例子，例如，每个key的窗口开始和结束都不一样，这需要Flink提供的窗口和检查点之间的分离(need the separation between windowing and checkpointing that Flink offers)。

(3) 版本控制应用程序状态：在纯数据流体系结构（通常称为Kappa体系结构）中，流是事件的持久记录，应用程序使用从流中计算出的状态进行工作。 在这样的体系结构中，Flink的分布式快照可用于“版本化”应用程序状态：可以升级应用程序而不会丢失瞬态状态，应用程序状态可以回滚到以前的版本（例如发现并纠正错误） 或者应用程序的不同变体可以被分离出某个状态（例如用于A / B测试）。

### 1. 乱序数据流和事件时间窗口

在讨论处理乱序数据流之前，我们需要定义顺序，从而定义时间。 流处理有两种时间概念：

- `事件时间`是事件在现实世界中发生的时间，通常是由事件发出的数据记录的时间戳表示。在几乎所有的数据流中，事件都带有表示事件产生时间的时间戳：Web服务器日志，来自监视代理的事件，移动应用日志，环境传感器数据等。

- `处理时间`是处理事件那台机器测量的时间。处理时间仅由运行流处理应用程序的机器的本地时钟来度量。

在许多流处理中，在应用程序(服务器日志，传感器，监视代理等)产生事件的时间与其到达消息队列中以供处理的时间之间存在可变的延迟。原因有很多：
- 在不同的网络路径上有不同的延迟
- 来自消费者的排队和背压影响
- 数据峰值速率
- 一些事件的生产者并不总是处于连接状态中(移动设备，传感器等)
- 一些发送爆发性事件的生产者

这样的最终影响是与事件时间相比事件在队列中经常是无序的。此外，事件产生的时间戳与事件到达队列或流处理器时间之间的差异随时间而变化。这通常被称为`事件时间倾斜`(event time skew)，并被定义为`处理时间-事件时间`(processing time – event time)。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Flink/Flink%20Stream%E6%8C%87%E5%8D%97%20%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E4%B8%8E%E6%97%A0%E5%BA%8F%E5%A4%84%E7%90%86-outoforder.png?raw=true)

对于许多分析应用程序来说，相对于根据它们到达消息队列或流处理系统时的分析，根据它们产生时间戳(即事件时间)来分析事件是迄今为止最令人感兴趣的结果(yields by far the most interesting results)：

- 来自外部传感器或监测系统的相关联事件(寻找共同模式)，如果他们同时产生，在同时处理事件时只给出有意义的结果(only meaningful results when treating events as simultaneous if they were produced simultaneously)。
- 统计事件发生(例如每分钟的信号)本质上是不准确的，除非参考事件时间(Computing statistics over event occurrence is inherently inaccurate)。
- 事件序列中检测模式需要有意义的事件顺序，通常是发生顺序，而不是到达顺序。

`Flink`允许用户基于事件时间定义窗口，不是处理时间。因此，窗口不易受乱序事件和不同事件时间偏差的影响。他们根据事件固有的时间(the time inherent to the events)来计算有意义的结果。Flink使用事件时间时钟追踪事件时间，使用`watermarks`实现。`watermarks`是在Flink的数据流源生成的特殊事件，大大提高了事件时间(coarsely advance event time)。时间T的水印表示事件时间在该特定流（或分区）中已经发展到T，这意味着没有时间戳小于T的事件可以再次到达。所有Flink运营商都可以根据这个时钟跟踪事件时间。下一节将深入探讨水印的概念以及Flink如何度量事件时间。下图显示了Flink如何在事件时间计算窗口。中心的观察是，没有一个窗口在流上移动，但是可能有许多并发窗口正在进行，根据事件时间戳分配事件。在水印到达时触发窗口计算并更新事件时钟。

































原文:https://data-artisans.com/blog/how-apache-flink-enables-new-streaming-applications-part-1
