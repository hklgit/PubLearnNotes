---
layout: post
author: sjf0115
title: Flink1.4 事件时间与无序处理
date: 2018-01-15 15:35:17
tags:
  - Flink

categories: Flink
---

流数据处理正在蓬勃发展，因为它可以提供最新新数据的更好洞察，以及从数据提取到分析的简化流程。现实世界中的数据生成一直是一个持续的过程(例如，Web服务器日志，移动应用程序中的用户活动，数据库事务或传感器读取数据)。正如其他人所指出的，到目前为止，大部分数据基础架构都是建立在这样的基本假设之上:`数据是有限和静态的`。

为了弥补连续数据生产和旧"批处理"系统局限性之间的这一根本差距，公司已经引入了复杂而脆弱(fragile)的端到端管道。现在流处理技术通过对数据进行建模和处理，从而减少了对复杂解决方案的需求，这些数据是以真实世界的事件形式出现的。

将数据建模以及将数据以流方式处理的想法当然不是最新的，市场上可用的数据流处理器也不是最新的。但是，一个新的流处理系统(包括Apache Flink)与旧的流处理系统(包括开源和专有的)提供了本质的区别。使用Flink进行数据流处理比传统概念上快速(实时)分析要应用广泛得多，包括对历史数据的分析，以及启用新一类的应用程序，这些应用程序很少或根本不使用以前旧技术。我们将详细研究一些应用程序，并展示Flink如何以及为何能够有效地支持这些应用程序：

(1) 无序数据的精准结果。在大多数流处理场景中，事件的顺序非常重要，通常事件到达数据处理集群的顺序与这些事件在现实世界中实际发生的时间不同。Flink是第一个开源系统，可以让开发人员控制事件时间，事件发生的时间，在乱序流处理中实现精确的结果。

(2) 会话和未对齐的窗口：对Web日志，机器日志和其他数据进行分析需要能够在会话中将事件进行分组。会话是未对齐窗口(unaligned windows)的一个典型例子，例如，每个key的窗口开始和结束都不一样，这需要Flink提供的窗口和检查点之间的分离(need the separation between windowing and checkpointing that Flink offers)。

(3) 版本控制应用程序状态：在纯数据流体系结构（通常称为Kappa体系结构）中，流是事件的持久记录，应用程序使用从流中计算出的状态进行工作。 在这样的体系结构中，Flink的分布式快照可用于“版本化”应用程序状态：可以升级应用程序而不会丢失瞬态状态，应用程序状态可以回滚到以前的版本（例如发现并纠正错误） 或者应用程序的不同变体可以被分离出某个状态（例如用于A / B测试）。

### 1. 乱序数据流和事件时间窗口

在讨论处理乱序数据流之前，我们需要定义顺序，从而定义时间。 流处理有两种时间概念：

- `事件时间`是事件在现实世界中发生的时间，通常是由事件发出的数据记录的时间戳表示。在几乎所有的数据流中，事件都带有表示事件产生时间的时间戳：Web服务器日志，来自监视代理的事件，移动应用日志，环境传感器数据等。

- `处理时间`是处理事件那台机器测量的时间。处理时间仅由运行流处理应用程序的机器的本地时钟来度量。

在许多流处理中，在应用程序(服务器日志，传感器，监视代理等)产生事件的时间与其到达消息队列中以供处理的时间之间存在可变的延迟。原因有很多：
- 在不同的网络路径上有不同的延迟
- 来自消费者的排队和背压影响
- 数据峰值速率
- 一些事件的生产者并不总是处于连接状态中(移动设备，传感器等)
- 一些发送爆发性事件的生产者

这样的最终影响是与事件时间相比事件在队列中经常是无序的。此外，事件产生的时间戳与事件到达队列或流处理器时间之间的差异随时间而变化。这通常被称为`事件时间倾斜`(event time skew)，并被定义为`处理时间-事件时间`(processing time – event time)。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Flink/Flink%20Stream%E6%8C%87%E5%8D%97%20%E4%BA%8B%E4%BB%B6%E6%97%B6%E9%97%B4%E4%B8%8E%E6%97%A0%E5%BA%8F%E5%A4%84%E7%90%86-outoforder.png?raw=true)

对于许多分析应用程序来说，相对于根据它们到达消息队列或流处理系统时的分析，根据它们产生时间戳(即事件时间)来分析事件是迄今为止最令人感兴趣的结果(yields by far the most interesting results)：

- 来自外部传感器或监测系统的相关联事件(寻找共同模式)，如果他们同时产生，在同时处理事件时只给出有意义的结果(only meaningful results when treating events as simultaneous if they were produced simultaneously)。
- 统计事件发生(例如每分钟的信号)本质上是不准确的，除非参考事件时间(Computing statistics over event occurrence is inherently inaccurate)。
- 事件序列中检测模式需要有意义的事件顺序，通常是发生顺序，而不是到达顺序。

`Flink`允许用户基于事件时间定义窗口，不是处理时间。因此，窗口不易受乱序事件和不同事件时间偏差的影响。根据事件固有的时间来计算出有意义的结果。`Flink`使用事件时间时钟追踪事件时间，并使用`watermarks`来实现。`watermarks`是在`Flink`的数据流源生成的特殊事件，大大提高了事件时间(coarsely advance event time)。时间T的`Watermark`表示事件时间在该流(或分区)上已经处理到时间T，这意味着不会再有小于T的时间戳事件可以到达。所有`Flink`算子都可以根据这个时钟跟踪事件时间。下一节将深入探讨`Watermark`的概念以及`Flink`如何度量事件时间。下图显示了`Flink`如何基于事件时间计算窗口。观察到的是没有一个窗口在流上移动，但是可能有许多窗口并发运行，根据事件时间戳把事件分配给窗口。在`Watermark`到达时触发窗口计算并更新事件时钟。

![]()

基于事件时间的管道会尽快产生精确的结果(一旦事件时间达到规定时间)，但必要的时候尽可能迟(把相关事件包含进来)。与使用批处理器周期性地计算聚合相比，流事件时间管道提早产生结果并且通常更精确(因为批处理管道不能正确处理跨批次的乱序事件)。最后，流式作业简单而明确地描述了如何按时间(窗口)对元素进行分组，以及如何评估必要的时间进度（水印），而不是将这种逻辑分发到(1)滚动接收文件中，(2)批量作业，(3)定期作业调度程序。

### 2. 整合事件时间和实时管道

事件时间管道会产生一定的延迟，因为需要等待所需的事件时间进度。在某些情况下，上述延迟太大，无法产生恰当的实时结果。在这种情况下，事件时间管道会替换离线批处理作业，或者向应用程序添加准确的短滞后时间结果。 因为`Flink`是一个合适的流处理器，可以在几毫秒内处理完事件，所以很容易就可以在同一个程序中将低延迟的实时管道与事件时间管道结合起来。下面的例子说明了一个生产程序：
- 低延迟警报，基于个别事件。如果发现某种类型的事件，则发送警报消息。
- 一个基于处理时间窗口的实时仪表板，每隔几秒就对事件进行聚合和计数。
- 根据事件时间准确统计。

![]()

整合事件时间和处理时间的另一种方式是定义具有提早发出结果以及最大延迟的事件时间窗口(to define event time windows with early results, or with a maximum lag)：
- 事件时间窗口可以自定义一个滞后于处理时间的最大延迟。例如，一个事件时间窗口将在事件时间内以`10：15h`关闭，可以自定义为在处理时间内不晚于`10：20h`关闭。
- 事件时间窗口可以提前发出结果。 例如，计算滑动15分钟事件时间窗口中的事件数量的程序可以在按处理时间每分钟发出当前每个未触发窗口的计数。

为了实现这种方法，`Flink`提供了窗口触发器。这些触发器定义了窗口应该被触发的条件。触发器可以对处理时钟，事件时钟，甚至数据流的内容作出反应。我们将在后续博客文章中深入了解触发器。

### 3. Flink如何度量时间

现在，我们深入了解`Flink`处理时间的机制，以及这些机制与旧式流式处理系统的不同之处。一般来说，时间是使用时钟度量的。最简单的时钟(称为挂钟)是正在执行流式作业集群的某些机器的内部时钟。挂钟记录处理时间。为了跟踪事件时间，我们需要一个时钟来度量不同机器的同一时间。这通过`Flink`的`Watermark`机制来完成。`Watermark`是一种特殊事件，表示指事件流中的时间(即，事件流中的真实世界时间戳)达到一个特定事件点(例如，10am)，并且从现在起不会有早于上午10点时间戳的事件到达。这些`Watermark`是常规事件数据流的一部分，`Flink`算子一旦从所有上游算子/数据源接收到`10am`的`Watermark`，就将其事件时间提前至上午10点。请注意，基于事件时钟追踪时间比处理时钟粒度更粗，但更为正确，因为它在机器间保持一致。第三种类型的时钟(我们称之为系统时钟)被流处理系统用于内部簿记，最重要的是保证一致的语义("精确一次处理")。`Flink`通过向数据流注入栅栏`Barriers`并绘制一致性的计算快照来跟踪作业的进度。`Barriers`类似于`Watermark`，因为它们都是流经数据流的事件。不同之处在于`Barriers`不是由真实世界的数据源产生的，而是根据`Flink master`的挂钟度量的。类似地，`Spark Streaming`基于`Spark`的接收器的挂钟调度微批次。`Flink`的快照机制和`Spark`的微批处理机制都是系统时钟的例子，这是一种追踪计算时间(以及进度)的方法。图片显示了如果我们"冻结"计算，不同的时钟可以测量不同的时间:

![]()

作业由一个数据源和一个并行执行在两台机器上(worker 1 和 worker 2)的窗口算子组成。事件中的数字表示它们的时间戳，并且它们框的颜色代表它们的键值(灰色事件转到窗口1，紫色事件转到窗口2)。数据源从队列(也是分区的)中读取事件，根据key对它们进行分区，将它们转发到正确的窗口算子实例中。窗口被定义为基于事件时间的时间窗口。我们看到，由于缺乏同步，不同机器(worker 1，worker 2 和 master)上的挂钟可能度量成不同的时间(分别为10,8和7，假设时间从0开始)。

来源发出水印，目前所有时间戳为4的水印已到达窗口操作员。 这意味着事件时钟测量4，并且这个时间在并行计算中是一致的。



























原文:https://data-artisans.com/blog/how-apache-flink-enables-new-streaming-applications-part-1
