---
layout: post
author: sjf0115
title: 深入理解HBase架构
date: 2019-11-09 15:22:07
tags:
  - HBase

categories: HBase
permalink: in-depth-look-hbase-architecture
---

在这篇博客文章中，我们主要深入看一下H Base 的体系结构以及在 NoSQL 数据存储解决方案主要优势。

### 1. HBase架构组件

从物理上来说 HBase 由主从模式架构的三种服务组成：HBase RRegionServer、HBase Master、Zookeeper：
- RegionServer 负责为读写提供数据服务。访问数据时，客户端可直接与 RegionServer 进行通信。
- HBase Master 进程负责 Region 分配，DDL（创建、删除表）操作等。
- Zookeeper 作为 HDFS 一部分的，负责维护活跃集群的状态。

Hadoop DataNode 负责存储 RegionServer 管理的数据。所有 HBase 的数据都存储在 HDFS 文件中。RegionServer 和 HDFS DataNode 往往会部署在一起，这样 RegionServer 就能够实现数据本地化（即将数据放在离需要尽可能近的地方）。HBase 在数据写入时是满足数据本地性的，但是随着 Region 的迁移，数据就可能不再满足本地性了，直到完成数据压缩才能恢复本地性。

NameNode 维护所有构成文件的物理数据块的元数据信息。

![](1)

### 2. Region

HBase 表根据 RowKey 的开始和结束范围水平拆分为多个 Region。每个 Region 都包含了 StartKey 和 EndKey 之间的所有行。每个 Region 都会分配到集群的一个节点上，即 RegionServer，由它们为读写提供数。RegionServer 大约可以管理 1,000 多个 Region。

![](2)

### 3. HBase Master

> 或称之为HMaster

分配 Region，DDL（创建，删除表）操作均由 HBase Master 处理。

Master具体负责：
- 协调 RegionServer：(1)在启动时分配 Region、在故障恢复或者负载均衡时重新分配 Region。(2)监听集群中的所有 RegionServer 实例（侦听来自 Zookeeper 的通知）。
- 管理员功能：创建，删除，更新表的接口。

![](3)

### 4. ZooKeeper

HBase 使用 ZooKeeper 作为分布式协调服务来维护集群中的服务状态。Zookeeper 维护哪些服务处于活跃状态并且是可用的，并提供服务故障通知。 Zookeeper 使用一致性协议来保证分布式状态的一致性。请注意，需要有三到五台机器来保证一致性协议。

![](4)

### 5. 组件如何协同工作

Zookeeper 用于协调分布式系统成员的共享状态信息。RegionServer 和活跃的 HMaster 通过与 Zookeeper 的会话连接。Zookeeper 通过心跳维护临时节点以进行活跃会话。

![](5)

每个 RegionServer 都会创建一个临时节点。HMaster 监视这些节点以发现可用的 RegionServer，并且还监视这些节点是否出现服务器故障。Zookeeper 使用第一个发现的 HMaster，确保只有它处于活跃状态，通创建一个临时节点来实现。活跃的 HMaster 将心跳发送到 Zookeeper，非活跃的 HMaster 则侦听活跃的 HMaster 故障的通知。

如果 RegionServer 或活跃的 HMaster 无法发送心跳，会导致会话过期，并会删除相应的临时节点。活跃的 HMaster 侦听 RegionServer，并恢复发生故障的 RegionServer。非活跃的 HMaster 侦听活跃的 HMaster 是否出现故障，如果活跃的 HMaster 发生故障，那么非活跃的一个 HMaster 会变为活跃状态。

### 6. HBase首次读写

HBase 中有一个特殊的目录表(META表)，该表保存了集群中所有 Region 的位置。ZooKeeper 存储 META 表的位置。

如下客户端第一次读写时发生的情况：
- 客户端从 ZooKeeper 获取负责管理 META 表的 RegionServer。
- 客户端查询 .META 服务来获取我们要访问的 RowKey 所对应的 RegionServer。客户端会将该信息与 META 表位置进行缓存。
- 客户端查询相应的 RegionServer，并从中获取行。

为了以后的读请求，客户端会缓存检索的 META 位置以及先前读取的 RowKey。在后面，我们一般不需要查询 META 表，除非由于 Region 迁移导致缓存失效；然后会重新查询并更新缓存。

![](6)

### 7. HBase Meta表

> 元数据表

- META 表是一个 HBase 表，用于保存系统中所有 Region 的列表。
- .META. 表类似一棵 B 树。
- .META. 表结构：(1)Key：Region 开始键，Region ID；(2)Value：RegionServer

![](7)

### 8. RegionServer组件

RegionServer 在 HDFS 数据节点上运行，并具有以下组件：
- WAL：预写日志是分布式文件系统上的一个文件。用于存储尚未持久存储的新数据，在出现故障时可以进行恢复。
- BlockCache：读缓存，将经常读取的数据存储在内存中。内存不足时删除最近最少使用的数据。
- MemStore：写缓存，存储尚未写入磁盘的新数据。在写入磁盘之前先对其进行排序。每个 Region 的每个列族都有一个 MemStore。
- HFile：将行以有序的 KeyValue 存储在磁盘上。

![](8)

### 9. HBase写入步骤

#### 9.1 第一步

当客户端发出 Put 请求时，第一步是将数据写入预写日志 WAL：
- 新内容将追加到 WAL 文件(存储在磁盘上)末尾。
- WAL用于恢复服务器崩溃时尚未持久化的数据。

![](9)

#### 9.2 第二步

将数据写入 WAL 后，并将其存储在 MemoryStore 中(写缓存)。然后将 Put 请求确认返回给客户端。

![](10)

### 10. HBase MemStore

MemStore 将更新存储为有序的 KeyValue，与存储在 HFile 中相同。每个列族只有一个 MemStore。更新是按列族排序的。

![](11)

### 11. HBase Region Flush

当 MemStore 累积足够多的数据时，整个有序集被写入到 HDFS 中的新 HFile。HBase 每个列族会有多个 HFile，这些 HFile 包含实际的单元值或 KeyValue 实例。HFile 会随着时间不断产生，因为存储在 MemStore  中的 KeyValue 会不断地刷写到硬盘上。

请注意，这也是为什么 HBase 中的列族数量有限的一个原因。每个列族都有一个 MemStore。当 MemStore 满之后就会刷写到硬盘。还会保存最后写入的序列号，以便系统知道到目前为止所持久化的内容。

最大序列号存储为每个 HFile 中的一个 meta 字段，以反映持久化在何处结束以及在何处继续。当 Region 启动时，会读取序列号，并将最大的序列号用作新编辑内容的序列号。

![](12)

### 12. HBase HFile

数据存储在 HFile 中，以有序键/值形式。当 MemStore 累积足够多的数据时，将整个有序 KeyValue 集写入到一个新的 HFile 中。以顺序写入，这会非常快，因为它避免了移动磁盘驱动器磁头。

![](13)

#### 12.1 HBase HFile 结构

HFile 包含多层索引，从而使 HBase 无需读取整个文件即可查找数据。多级索引类似一个 B+ 树：
- 键值对以升序存储
- Rowkey 对应索引指向 64KB 大小的数据块
- 每个数据块都有自己的叶子索引
- 每个数据块的最后一个键放在中间索引中
- 根索引指向中间索引

> 三种索引类型：(1) Root Index：根索引 (2) Intermediate Index：中间索引 (3) Leaf Index：叶子索引

Trailer 指向 meta 数据块，并将数据写入到持久化文件的末尾。Trailer 还包含诸如布隆过滤器和时间范围之类的信息。布隆过滤器可以帮助我们跳过不包含在特定行键的文件。时间范围信息可以帮助我们跳过不在读取的时间范围内的文件。

![](14)

#### 12.2 HFile索引

刚才我们讨论的索引，在 HFile 被打开时会被载入内存，这样数据查询只要一次硬盘查询。

![](15)

### 13. HBase Read Merge

我们已经看到，对应于一行的 KeyValue 单元可以存储在多个位置，已经持久化的行单元位于 HFiles 中，最近更新的单元位于 MemStore 中，而最近读取的单元位于 BlockCache 中。因此，当我们读取一行时，系统如何获取对应的单元返回？读取操作需要通过以下步骤合并来 BlockCache、MemStore 以及 HFiles 中的键值：
- 首先，扫描程序在 BlockCache(读缓存) 中查找行单元。最近读取过的键值存储在这里，并且在内存不足时需要删除最近最少使用的数据。
- 接下来，扫描程序在 MemStore(写缓存) 中查找，这里包含最近的写入。
- 如果扫描程序在 MemStore 和 BlockCache 中没有找到所有行单元，那么 HBase 将使用 BlockCache 索引和布隆过滤器将 HFiles 加载到内存中，这里可能包含目标行单元。

![](16)

如前所述，每个 MemStore 可能有多个 HFile，这意味着对于读操作而言，可能必须查找多个文件，这可能会影响性能。这称为读取放大。

### 14. HBase压缩

#### 14.1 Minor压缩

HBase 会自动选择一些较小的 HFile，将它们重写合并为一些较大的 HFile。 此过程称为 Minor 压缩。这样通过将比较多且较小的文件重写为比较少但较大的文件可以减少存储文件的数量。

![](17)

#### 14.2 Major压缩

Major 压缩会将一个 Region 中的所有 HFile 合并并重写为每个列族一个 HFile，在此过程中，删除已删除或已过期的单元。这样可以提高读取性能；但是，由于 Major 压缩会重写所有文件，因此在此过程中可能会发生大量磁盘 I/O 和网络流量。这称为写放大。

Major 压缩可以调度为自动运行。由于写入放大，通常在周末或晚上进行 Major 压缩。Major 压缩还可以使由于服务器故障或负载平衡而变成远程文件重新回到 RegionServer 数据本地性。

![](18)

### 15. Region = Contiguous Keys

让我们快速了解一下 Region：
- 一个表可以水平拆分为一个或多个 Region。Region 在开始键和结束键之间包含连续的，有序的行
- 每个 Region 的默认大小为1GB
- 表的 Region 由 RegionServer 提供给客户端
- RegionServer 大约可以管理 1,000个 Region（可能属于同一表或不同表）

![](19)

### 16. Region拆分

最初，每个表只有一个 Region。当 Region 过大时，会分为两个子 Region。两个子 Region（代表原始 Region 的一半）可以在同一 RegionServer 上并行打开，拆分会报告给 HMaster。出于负载平衡的原因，HMaster 可能会将新 Region 迁移到其他服务器。

![](20)

### 17. 读取负载均衡

拆分最初发生在同一个 RegionServer 上，但是出于负载均衡的考虑，HMaster 可能会将新 Region 迁移至其他服务器。这会导致新的 RegionServer 从远程 HDFS 节点上提供数据，直到进行 Major 压缩才将数据文件移动到新的 RegionServer 的本地节点。HBase 数据在写入时是在本地节点的，但是在迁移 Region 时(用于负载均衡或故障恢复)，会丢失数据本地性。

> Region 迁移只是逻辑上的迁移，数据还在原先的 RegionServer 上，只是 Region 交给新的 RegionServer 管理。

![](21)

### 18. HDFS数据备份

所有读写请求都来自/发往主节点。HDFS 会备份 WAL 和 HFile 数据块。HFile 数据块备份会自动进行。HBase 依赖 HDFS 来保证存储文件的数据安全。当数据写入 HDFS 时，一个副本写入本地，然后将其备份到辅助节点，而第三个副本被写入第三节点。

![](22)

WAL 文件和 HFiles 被持久化到磁盘上并被备份，那么 HBase 如何恢复在 MemStore 中更新但未持久到 HFiles 中的数据？答案请参见下一部分。

### 19. HBase故障恢复

当 RegionServer 发生故障时，崩溃的 Region 不可用，直到发生检测和恢复步骤为止。当失去 RegionServer 心跳信号时，Zookeeper 认定为节点发生故障。然后，HMaster 将被告知 RegionServer 发生故障。

当 HMaster 检测到 RegionServer 崩溃时，HMaster 将发生崩溃的 RegionServer 中的 Region 重新分配给活跃的 RegionServer。为了恢复崩溃的 RegionServer 中的 MemStore 内容(还未刷写到磁盘)。HMaster 将属于崩溃 RegionServer 的 WAL 拆分为不同的文件，并将这些文件存储在新 RegionServer 的数据节点中。然后，每个 RegionServer 回放各自拿到的拆分的 WAL，以重建该 MemStore。

![](23)

### 20. 数据恢复

WAL 文件包含一系列编辑，其中每一个编辑都表示一个 Put 或 Delete。编辑是按时间顺序写入的，因此，持久化时将内容追加到存储在磁盘上的 WAL 文件的末尾。

如果数据仍在内存中但未持久化保存到 HFile 时发生故障，该怎么办？重放 WAL。通过读取 WAL，将包含的编辑内容追加到当前的 MemStore 并对其进行排序来完成 WAL 的重放。最后，刷写 MemStore 以将更改写入 HFile。

![](24)




原文:[An In-Depth Look at the HBase Architecture](https://mapr.com/blog/in-depth-look-hbase-architecture/)
