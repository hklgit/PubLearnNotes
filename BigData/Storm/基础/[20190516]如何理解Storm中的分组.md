---
layout: post
author: sjf0115
title: 如何使用Storm的分组策略
date: 2019-05-18 17:19:21
tags:
  - Storm
  - Storm 基础

categories: Storm
permalink: how-to-use-grouping-of-storm
---


在设计拓扑之前，定义数据如何在不同组件之间传送是非常重要的。流分组指定了每个 Bolt 消费哪个数据流以及是如何消费的。

Storm 支持一下几种流式分组:
- Shuffle grouping
- Fields grouping
- All grouping
- Global grouping
- Direct grouping
- Local or shuffle grouping
- Custom grouping
- None grouping

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/how-to-use-grouping-of-storm-1.png?raw=true)

### 1. Shuffle grouping

随机分组是最常用的一种分组策略。随机分组统一随机的在任务之间分发元组，是一种将元组随机分发到任务中的一种分组方式。使用随机分组，每个任务尽可能的处理相等数量的元组，这样可以实现算子之间的负载均衡。需要注意的是，随机分组采用的是随机策略而不是轮询策略，所以并不能保证严格的均分。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/how-to-use-grouping-of-storm-2.png?raw=true)

随机分组在你对数据如何分发上没有特殊要求的场景下非常有用。

具体看一下数据流转:

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Storm/how-to-use-grouping-of-storm-3.png?raw=true)

### 2. Fields grouping

字段分组可以基于元组中的一个或者多个字段对流进行分区。可以确保指定字段上相同的元组总是发送到同一个任务上。

![]()

例如，如果你希望来自特定用户的所有推文都发送到同一个任务上，那么你可以使用如下方式在 `username` 字段上使用字段分组来对推文流进行分区：
```java
builder.setSpout("1", new TweetSpout());
builder.setBolt("2", new TweetCounter()).fieldsGrouping("1", new Fields("username"))
```
字段分组使用如下函数计算：
```
hash (fields) % (no. of tasks)
```
在这里，hash 是一个散列函数。字段分组并不能保证每个任务都会得到元组来处理(即，某些任务上有可能没有元组处理，处于空闲状态)。例如，如果你在字段 x 上使用字段分组，字段 x 只有两个可能的值 A 和 B，同时为 Bolt 创建了两个任务，那么 `hash(A)％2` 和 `hash(B)％2` 可能是相等的，这会导致所有元组被分组其中的一个任务上而另一个任务完全空闲。

字段分组的另一个常见用法是数据流合并。由于分区仅基于字段值而不是流类型，因此我们可以使用任何常用合并字段来合并两个流，字段的名称没有必要相同。例如如下，我们可以在一个订单完成时合并 Order 和 ItemScanned 流：
```java
builder.setSpout("1", new OrderSpout());
builder.setSpout("2", new ItemScannedSpout());
builder.setBolt("joiner", new OrderJoiner())
  .fieldsGrouping("1", new Fields("orderId"))
  .fieldsGrouping("2", new Fields("orderRefId"));
```

### 3. All grouping

所有分组都是一个特殊的分组，不对元组进行分区，而是将它们复制到所有任务中，也就是说，每个元组都会被发送到所有 Bolt 任务中进行处理。

所有分组的一个常见用法是给 Bolt 任务发送信号。例如，如果要对流进行过滤，那么必须将过滤器参数传递给所有 Bolt 任务。这可以通过向所有 Bolt 任务订阅的数据流上发送这些参数来实现。另一个示例是向聚合 Bolt 中的所有任务发送重置消息。

![]()

以下是所有分组的示例：
```java
builder.setSpout("1", new TweetSpout());
builder.setSpout("signals", new SignalSpout());
builder.setBolt("2", new TweetCounter()).fieldsGrouping("1",
new Fields("username")).allGrouping("signals");
```
在这里，我们为所有 TweetCounter bolt 任务订阅信号。现在，我们可以使用 SignalSpout 向 TweetCounter Bolt 发送不同的信号。

### 4. Global grouping

全局分组不对流进行分区，而是将数据源所有实例产生的元组发送到 ID 最小的 Bolt 任务上。

![]()

全局分组的常用用法是，在拓扑的 Reduce 阶段，在一个 Bolt 任务中聚合拓扑前一步骤的结果。全局分组起初看起来像是多余的，因为你可以将 Bolt 的并行度设置为 1 并只设置一个输入流也可以实现相同的结果。但是，当你有多个来自不同路径的数据流时，你只希望其中一个数据流 Reduce ，而其他数据流并行处理。

例如如下拓扑，在这个拓扑中，你可能希望将来自 Bolt C 的所有元组发送到 Bolt D 一个任务上，同时也希望从 Bolt E 到 Bolt D 的元组并行处理：

![]()

```java
builder.setBolt("c", new BoltC());
builder.setBolt("e", new BoltE());
builder.setBolt("d", new BoltD())
  .globalGrouping("c")
  .shuffleGrouping("e");
```

### 5. Direct grouping

在直接分组中，元组可以指定由具体的某个任务来处理，具体是哪个任务由发射器决定。例如，假设我们有一个日志流，我们希望根据资源类型使用指定的 Bolt 任务处理每个日志条目。在这种情况下，我们可以使用直接分组。

直接分组只能与直接流一起使用。如果要将流声明为直接流，需要在 Spout 中将 `backtype.storm.topology.OutputFieldsDeclarer.declareStream` 方法的布尔参数设置为 true：
```java
@Override
public void declareOutputFields(OutputFieldsDeclarer declarer) {
  declarer.declareStream("directStream", true, new Fields("field1"));
}
```
现在，我们需要获取组件的任务数，以便我们可以在发送元组时通过 TaskId 发送到指定的任务上。这可以在 Bolt 的 prepare 方法中通过 `backtype.storm.task.TopologyContext.getComponentTasks` 方法来计算。如下代码在 Bolt 中获取任务数：
```java
public void prepare(Map stormConf, TopologyContext context, OutputCollector collector) {
  this.numOfTasks = context.getComponentTasks("my-stream");
  this.collector = collector;
}
```
一旦有直接流要发送，需要使用 `backtype.storm.task.OutputCollector.emitDirect` 方法发送而不是我们常用的 `emit` 方法。`emitDirect` 方法接受 taskId 参数来指定具体的任务。在下面的代码片段中，我们随机发送到一个任务：
```java
public void execute(Tuple input) {
  collector.emitDirect(new Random().nextInt(this.numOfTasks), process(input));
}
```
以下是直接分组的实例：
```java
builder.setBolt("word-counter", new WordCounter(),2).directGrouping("word-normalizer");
```

### 6. Local or shuffle grouping

如果元组源和目标 Bolt 任务在同一个 worker 中运行，使用此分组策略可以理解为仅作为在同一 worker 上运行的任务之间的随机分组，从而最大限度地减少任何网络传输，从而提高性能。

如果源工作进程上没有运行目标 Bolt 任务，则此分组策略的行为类似于前面提到的随机分组。

### 7. Custom grouping

如果前面的分组策略都没有适合的，你可以通过实现 `backtype.storm.grouping.CustomStreamGrouping` 接口来实现自己的自定义分组策略。

以下是基于元组中的类别对流进行分区的自定义分组示例：
```java
public class CategoryGrouping implements CustomStreamGrouping, Serializable {
  // Mapping of category to integer values for grouping
  private static final Map categories = ImmutableMap.of(
    "Financial", 0,
    "Medical", 1,
    "FMCG", 2,
    "Electronics", 3
  );

  // number of tasks, this is initialized in prepare method
  private int tasks = 0;

  public void prepare(WorkerTopologyContext context, GlobalStreamId stream, List targetTasks){
    // initialize the number of tasks
    tasks = targetTasks.size();
  }

  public List chooseTasks(int taskId, List values) {
    // return the taskId for a given category
    String category = (String) values.get(0);
    return ImmutableList.of(categories.get(category) % tasks);
  }
}
```
现在，我们可以使用如下代码在拓扑中使用此分组：
```java
builder.setSpout("a", new SpoutA());
builder.setBolt("b", (IRichBolt)new BoltB())
  .customGrouping("a", new CategoryGrouping());
```

### 8. None Grouping

在这种分组中，用户不需要关心哪个 Bolt 处理哪个元组。目前，与随机分组的实现方式相同。元组随机分发到 Bolt 中，以便每个任务获得相同数量的元组。




英译对照：
- 随机分组: Shuffle grouping
- 直接流: direct streams

原文:[]()

http://www.corejavaguru.com/bigdata/storm/stream-groupings
https://www.youtube.com/watch?v=JTukr1Tqq48
https://blog.csdn.net/luonanqin/article/details/40436397
https://hub.packtpub.com/stream-grouping/
https://www.simplilearn.com/apache-storm-advanced-concepts-tutorial-video
