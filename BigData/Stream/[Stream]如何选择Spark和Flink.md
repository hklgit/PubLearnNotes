
围绕Spark和Flink有很多讨论，同时，关于何时使用Spark以及何时使用Flink也存在很多问题。下面将比较Spark和Flink的几个功能，并提供一些用例，帮助你决定何时使用Spark Streaming以及何时使用Flink。

Spark Streaming和Flink都能提供 Exactly Once 语义的保证，即每条记录都仅处理一次。与其他处理系统（比如Storm）相比，它们都能提供一个非常高的吞吐量。

两个处理引擎的容错开销都很低。Spark Streaming和Flink的不同之处在于其计算模型。Spark采用了微批处理，Flink采用了连续流，基于算子的流处理模型。

就窗口而言，Spark具有基于时间的窗口标准，而Flink具有基于记录或任何自定义的窗口。虽然Spark提供可配置的内存管理，但Flink提供自动内存管理，Spark 1.6的最新版本已经转向自动化内存管理。

看了Spark和Flink的各种功能，让我们看看三种不同类型的计算模式，即批量，微批和连续流操作。什么是批处理本质上就是处理静态数据，一次获取大量数据进行处理，然后输出。微批处理结合了批处理和连续流操作符，将输入分成多个微批次进行处理。从根本上讲，微批处理是一个"收集然后处理"的计算模型。连续流操作符则在数据到达时进行处理，没有任何数据收集或处理延迟。

我们举个例子进行一个类比，想象一下我们用桶收集水，然后把它倒出来，而不是在那里放一根管子，让水连续流动，没有任何的中间延迟。这基本上是微批次和连续流动操作符之间的差异。

Spark一开始是作为批处理器使用的，并添加越来越多的功能，使其能够进行实时流处理。Flink最初在研究阶段解决批处理问题，但随着研究发现，研究人员发现了实时流处理模式中的几个有趣问题。因此，他们更多的认为是基于连续流操作符的模型以及将批处理看作为实时流处理的一种特殊情况。

在决定使用批量，微批量或连续流操作符哪一个时，需要进行多种权衡，主要是延迟，吞吐量和可靠性。

为什么是延迟？延迟为何如此重要？传统观点认为数据具有价值，并且它具有很大的价值，与数据的年龄无关紧要。当处理能力增加时，企业开始意识到在数据发生时或收集数据时信息的价值最高。他们希望在数据发生时就可以处理数据，这就需要一个实时处理系统。

现在，我将讨论一些示例用例，这些用例基于是否针对您的特定用例使用微批量或实时流式传输。 我要谈的第一个用例是金融，我将谈论信用卡检测。 信用卡欺诈检测可以实时或微批发生，但与此同时，检测与欺诈预防非常不同。 检测是在微批或实时流上发生的事情，而欺诈预防必须实时发生。 想象一下，用户正在进行交易，您希望系统查看是欺诈性交易还是有效交易。






















原文：http://www.infoq.com/cn/news/2016/03/Apache-Spark-Apache-Flink-choose

https://mapr.com/blog/apache-spark-vs-apache-flink-whiteboard-walkthrough/
